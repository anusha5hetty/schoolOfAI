{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment4_Session4.ipynb","version":"0.3.2","provenance":[{"file_id":"10QI1BU3HnanXvELtZCwgTxVZP2dEoLh7","timestamp":1558543467604},{"file_id":"12Hymhsn_0NEBPNAzozWlouyDgy-cKIzK","timestamp":1558540795335},{"file_id":"1gZYwZdkgXBJRr624SqWJ9f452BmKNkNT","timestamp":1557891945033},{"file_id":"1JURGwe4e5Z7928Zv2eiJVPCQNc702huM","timestamp":1521864568638}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7tfzQauSGbtW","colab_type":"text"},"source":["## Objective & Observation:\n","\n","Objective:\n"," - Increasing the batch size to 64 to check if the model trains better\n"," - Adding Dropout of 0.1 after every convolution step instead of two 0.2 dropouts after each covolution block - to check if it addresses the overfitting problem better and the model is trained better  \n"," - Start the learning rate at 0.003 and decrease it after each epoch - \n","Reason:  In all the previous model, the accuracy is inconsistent, it increases to 99.25 at 13th epoch and decreases and increases to 99.27 at 20th epoch. this is because of have same learning rate.\n","\n","\n","\n","---\n","\n","\n","Observation:\n","- After increasing the batch size to 64\n","    - The model trained faster\n","    - There was no major change in the validation accuracy\n","- After adding Dropout of 0.1 \n","    - The accuracy improves and Test Accuracy of 99.40 is achieved\n","- After changing the learning rate to 0.003 and decreasing it after each epoch\n","    - Test Accuracy of 99.43 is achieved in 18th epoch"]},{"cell_type":"code","metadata":{"id":"3m3w1Cw49Zkt","colab_type":"code","outputId":"efab0109-be69-45d5-c2e8-f65409423386","executionInfo":{"status":"ok","timestamp":1558792293945,"user_tz":-330,"elapsed":9117,"user":{"displayName":"Anusha Shetty","photoUrl":"https://lh4.googleusercontent.com/-EhNj3Y4A6O8/AAAAAAAAAAI/AAAAAAAAD6g/ZGypcZ-Aupw/s64/photo.jpg","userId":"15947158711655021589"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# https://keras.io/\n","!pip install -q keras\n","import keras"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Eso6UHE080D4","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","from keras.models import Sequential\n","\n","from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n","\n","\n","from keras.layers import Convolution2D, MaxPooling2D\n","from keras.utils import np_utils\n","\n","from keras.datasets import mnist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7eRM0QWN83PV","colab_type":"code","colab":{}},"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g8yqpTyuP50L","colab_type":"text"},"source":["*   Printing the number of data in X_train, dimension of each image and plotting the first image in X_train\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"4a4Be72j8-ZC","colab_type":"code","outputId":"4223b6d1-7a00-4fa1-b169-a9cde3f50969","executionInfo":{"status":"ok","timestamp":1558792296848,"user_tz":-330,"elapsed":1182,"user":{"displayName":"Anusha Shetty","photoUrl":"https://lh4.googleusercontent.com/-EhNj3Y4A6O8/AAAAAAAAAAI/AAAAAAAAD6g/ZGypcZ-Aupw/s64/photo.jpg","userId":"15947158711655021589"}},"colab":{"base_uri":"https://localhost:8080/","height":305}},"source":["print (X_train.shape)\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","plt.imshow(X_train[500])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7ff445677358>"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"dkmprriw9AnZ","colab_type":"code","colab":{}},"source":["X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2m4YS4E9CRh","colab_type":"code","colab":{}},"source":["X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ZsX_SXHHu7A","colab_type":"text"},"source":["*   displays the first 10 output values in the output training dataset"]},{"cell_type":"code","metadata":{"id":"0Mn0vAYD9DvB","colab_type":"code","outputId":"e989423a-b41c-44cb-b434-8b026c597a45","executionInfo":{"status":"ok","timestamp":1558792299994,"user_tz":-330,"elapsed":652,"user":{"displayName":"Anusha Shetty","photoUrl":"https://lh4.googleusercontent.com/-EhNj3Y4A6O8/AAAAAAAAAAI/AAAAAAAAD6g/ZGypcZ-Aupw/s64/photo.jpg","userId":"15947158711655021589"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["y_train[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"Q1Hex2OQH4xW","colab_type":"text"},"source":["* Converts each value in the output training and testing dataset into vector of dimension 1xnumber_of_classes\n","* The values in the vector will be 0. or 1. \n","* Only one of the values in each vector will be 1, indicating the class to which the input data belongs to. Eg the first value in the y_train is 5, this will be converted into  [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]. \n","* The 6th value in the vector will be 1 indicating class 5.\n","* The first value in the vector represents class 0, second value represents class 1 and so on.\n","\n","* Convert 1-dimensional class arrays to 10-dimensional class matrices"]},{"cell_type":"code","metadata":{"id":"ZG8JiXR39FHC","colab_type":"code","colab":{}},"source":["# Convert 1-dimensional class arrays to 10-dimensional class matrices\n","Y_train = np_utils.to_categorical(y_train, 10)\n","Y_test = np_utils.to_categorical(y_test, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rlEsx8NqUYYQ","colab_type":"text"},"source":["* displays the first 10 output values in the output training dataset after conversion to vectors\n"]},{"cell_type":"code","metadata":{"id":"fYlFRvKS9HMB","colab_type":"code","outputId":"141ddfb4-979b-4241-b57c-31d92abf45ba","executionInfo":{"status":"ok","timestamp":1558792302740,"user_tz":-330,"elapsed":735,"user":{"displayName":"Anusha Shetty","photoUrl":"https://lh4.googleusercontent.com/-EhNj3Y4A6O8/AAAAAAAAAAI/AAAAAAAAD6g/ZGypcZ-Aupw/s64/photo.jpg","userId":"15947158711655021589"}},"colab":{"base_uri":"https://localhost:8080/","height":199}},"source":["Y_train[:10]\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"-53dZnNIdaFH","colab_type":"text"},"source":["## Training DNN Model"]},{"cell_type":"code","metadata":{"id":"osKqT73Q9JJB","colab_type":"code","outputId":"ff64b51c-1fac-465c-f5ce-8ca4b6f4d4ca","executionInfo":{"status":"ok","timestamp":1558792405929,"user_tz":-330,"elapsed":2802,"user":{"displayName":"Anusha Shetty","photoUrl":"https://lh4.googleusercontent.com/-EhNj3Y4A6O8/AAAAAAAAAAI/AAAAAAAAD6g/ZGypcZ-Aupw/s64/photo.jpg","userId":"15947158711655021589"}},"colab":{"base_uri":"https://localhost:8080/","height":201}},"source":["from keras.layers import Activation\n","model = Sequential()\n","\n","model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1))) # 26, RF: 3\n","model.add(BatchNormalization())\n","\n","# Convolution block 1\n","model.add(Convolution2D(16, 3, 3, activation='relu')) #24, RF: 5\n","model.add(BatchNormalization())\n","model.add(Dropout(0.1))\n","model.add(Convolution2D(20, 3, 3, activation='relu')) #22, RF: 7\n","model.add(BatchNormalization())\n","model.add(Dropout(0.1))\n","\n","# model.add(Dropout(0.3))\n","\n","# Transition block 1\n","model.add(MaxPooling2D(pool_size=(2, 2))) # 11, RF: 14\n","model.add(Convolution2D(8, 1, 1, activation='relu')) # 11, RF: 14\n","model.add(BatchNormalization())\n","model.add(Dropout(0.1))\n","\n","\n","# Convolution block 2\n","model.add(Convolution2D(16, 3, 3, activation='relu')) #9, RF: 16\n","model.add(BatchNormalization())\n","model.add(Dropout(0.1))\n","model.add(Convolution2D(20, 3, 3, activation='relu')) #7, RF: 18\n","model.add(BatchNormalization())\n","model.add(Dropout(0.1))\n","\n","# model.add(Dropout(0.3))\n","\n","model.add(Convolution2D(10, 1, activation='relu')) #7, RF: 18\n","model.add(BatchNormalization())\n","model.add(Convolution2D(10, 7))\n","\n","model.add(Flatten())\n","model.add(Activation('softmax'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (3, 3), activation=\"relu\")`\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (3, 3), activation=\"relu\")`\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"TzdAYg1k9K7Z","colab_type":"code","outputId":"fb1d5ebe-5b7b-4b5c-c23e-554d4630ab5d","executionInfo":{"status":"ok","timestamp":1558792409437,"user_tz":-330,"elapsed":759,"user":{"displayName":"Anusha Shetty","photoUrl":"https://lh4.googleusercontent.com/-EhNj3Y4A6O8/AAAAAAAAAAI/AAAAAAAAD6g/ZGypcZ-Aupw/s64/photo.jpg","userId":"15947158711655021589"}},"colab":{"base_uri":"https://localhost:8080/","height":981}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_9 (Conv2D)            (None, 26, 26, 8)         80        \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 26, 26, 8)         32        \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 24, 24, 16)        1168      \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 24, 24, 16)        64        \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 24, 24, 16)        0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 22, 22, 20)        2900      \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 22, 22, 20)        80        \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 22, 22, 20)        0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 11, 11, 20)        0         \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 11, 11, 8)         168       \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 11, 11, 8)         32        \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 11, 11, 8)         0         \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 9, 9, 16)          1168      \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 9, 9, 16)          64        \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 9, 9, 16)          0         \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 7, 7, 20)          2900      \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 7, 7, 20)          80        \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 7, 7, 20)          0         \n","_________________________________________________________________\n","conv2d_15 (Conv2D)           (None, 7, 7, 10)          210       \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 7, 7, 10)          40        \n","_________________________________________________________________\n","conv2d_16 (Conv2D)           (None, 1, 1, 10)          4910      \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 10)                0         \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 10)                0         \n","=================================================================\n","Total params: 13,896\n","Trainable params: 13,700\n","Non-trainable params: 196\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KDpMppc8fyZN","colab_type":"text"},"source":["* Compiles the convolution model. \n","* Compile method takes 3 parameters - loss, optimizer, metrics\n","* loss - lower the score, better the performance. value: categorical_crossentropy (commonly used)\n","* optimizer - controls the learning rate (determines how fast the optimal weights for the model are calculated)\n","* metrics - displays the accuracy metrics. indicates the accuracy of the trained model "]},{"cell_type":"code","metadata":{"id":"Zp6SuGrL9M3h","colab_type":"code","colab":{}},"source":["from keras.optimizers import Adam\n","from keras.callbacks import LearningRateScheduler\n","\n","def scheduler(epoch, lr):\n","  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QZguu-z_WLJ3","colab_type":"text"},"source":["## Observation\n","- After increasing the batch size to 64\n","    - The model trained faster\n","    - There was no major change in the validation accuracy\n","- After adding Dropout of 0.1 \n","    - The accuracy improves and Test Accuracy of 99.40 is achieved\n","- After changing the learning rate to 0.003 and decreasing it after each epoch\n","    - Test Accuracy of 99.43 is achieved in 18th epoch\n","\n"]},{"cell_type":"code","metadata":{"id":"4xWoKhPY9Of5","colab_type":"code","outputId":"20c5785c-6c9a-4e23-a88f-98d8489a1729","executionInfo":{"status":"ok","timestamp":1558792773107,"user_tz":-330,"elapsed":352805,"user":{"displayName":"Anusha Shetty","photoUrl":"https://lh4.googleusercontent.com/-EhNj3Y4A6O8/AAAAAAAAAAI/AAAAAAAAD6g/ZGypcZ-Aupw/s64/photo.jpg","userId":"15947158711655021589"}},"colab":{"base_uri":"https://localhost:8080/","height":1619}},"source":["model.fit(X_train, Y_train, batch_size=64, nb_epoch=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","\n","Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n","60000/60000 [==============================] - 25s 420us/step - loss: 0.1590 - acc: 0.9497 - val_loss: 0.0543 - val_acc: 0.9837\n","Epoch 2/20\n","\n","Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n","60000/60000 [==============================] - 18s 304us/step - loss: 0.0555 - acc: 0.9830 - val_loss: 0.0404 - val_acc: 0.9868\n","Epoch 3/20\n","\n","Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n","60000/60000 [==============================] - 18s 308us/step - loss: 0.0423 - acc: 0.9866 - val_loss: 0.0434 - val_acc: 0.9848\n","Epoch 4/20\n","\n","Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n","60000/60000 [==============================] - 18s 302us/step - loss: 0.0383 - acc: 0.9876 - val_loss: 0.0261 - val_acc: 0.9912\n","Epoch 5/20\n","\n","Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n","60000/60000 [==============================] - 19s 313us/step - loss: 0.0322 - acc: 0.9898 - val_loss: 0.0349 - val_acc: 0.9892\n","Epoch 6/20\n","\n","Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n","60000/60000 [==============================] - 19s 316us/step - loss: 0.0281 - acc: 0.9905 - val_loss: 0.0300 - val_acc: 0.9894\n","Epoch 7/20\n","\n","Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n","60000/60000 [==============================] - 18s 303us/step - loss: 0.0253 - acc: 0.9918 - val_loss: 0.0274 - val_acc: 0.9910\n","Epoch 8/20\n","\n","Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n","60000/60000 [==============================] - 18s 306us/step - loss: 0.0235 - acc: 0.9921 - val_loss: 0.0235 - val_acc: 0.9923\n","Epoch 9/20\n","\n","Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n","60000/60000 [==============================] - 19s 316us/step - loss: 0.0213 - acc: 0.9929 - val_loss: 0.0281 - val_acc: 0.9919\n","Epoch 10/20\n","\n","Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n","60000/60000 [==============================] - 20s 330us/step - loss: 0.0207 - acc: 0.9934 - val_loss: 0.0241 - val_acc: 0.9927\n","Epoch 11/20\n","\n","Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n","60000/60000 [==============================] - 18s 294us/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0229 - val_acc: 0.9926\n","Epoch 12/20\n","\n","Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n","60000/60000 [==============================] - 20s 334us/step - loss: 0.0180 - acc: 0.9939 - val_loss: 0.0218 - val_acc: 0.9938\n","Epoch 13/20\n","\n","Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n","60000/60000 [==============================] - 19s 322us/step - loss: 0.0162 - acc: 0.9944 - val_loss: 0.0227 - val_acc: 0.9938\n","Epoch 14/20\n","\n","Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n","60000/60000 [==============================] - 21s 347us/step - loss: 0.0158 - acc: 0.9948 - val_loss: 0.0199 - val_acc: 0.9937\n","Epoch 15/20\n","\n","Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n","60000/60000 [==============================] - 19s 321us/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0213 - val_acc: 0.9936\n","Epoch 16/20\n","\n","Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n","60000/60000 [==============================] - 14s 232us/step - loss: 0.0140 - acc: 0.9954 - val_loss: 0.0227 - val_acc: 0.9933\n","Epoch 17/20\n","\n","Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n","60000/60000 [==============================] - 11s 185us/step - loss: 0.0140 - acc: 0.9950 - val_loss: 0.0245 - val_acc: 0.9931\n","Epoch 18/20\n","\n","Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n","60000/60000 [==============================] - 11s 186us/step - loss: 0.0140 - acc: 0.9956 - val_loss: 0.0192 - val_acc: 0.9943\n","Epoch 19/20\n","\n","Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n","60000/60000 [==============================] - 11s 191us/step - loss: 0.0129 - acc: 0.9959 - val_loss: 0.0200 - val_acc: 0.9940\n","Epoch 20/20\n","\n","Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n","60000/60000 [==============================] - 12s 200us/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0201 - val_acc: 0.9948\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff430571710>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"AtsH-lLk-eLb","colab_type":"code","colab":{}},"source":["score = model.evaluate(X_test, Y_test, verbose=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkX8JMv79q9r","colab_type":"code","outputId":"d0c72344-684a-4442-877e-28d3eea44458","executionInfo":{"status":"ok","timestamp":1558539356855,"user_tz":-330,"elapsed":1387,"user":{"displayName":"Anusha Shetty","photoUrl":"https://lh4.googleusercontent.com/-EhNj3Y4A6O8/AAAAAAAAAAI/AAAAAAAAD6g/ZGypcZ-Aupw/s64/photo.jpg","userId":"15947158711655021589"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0.036891890601335214, 0.9886]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2oyNzuGbYxK7","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"dWIxMnNZg2om","colab_type":"text"},"source":["* The trained model predicts the output for all the input dataset in X_test\n"]},{"cell_type":"code","metadata":{"id":"OCWoJkwE9suh","colab_type":"code","colab":{}},"source":["y_pred = model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ym7iCFBm9uBs","colab_type":"code","outputId":"ba0cd5ed-a61f-47d7-fcbe-230b5666e0b2","executionInfo":{"status":"ok","timestamp":1558001503692,"user_tz":-330,"elapsed":813,"user":{"displayName":"Anusha Shetty","photoUrl":"https://lh4.googleusercontent.com/-EhNj3Y4A6O8/AAAAAAAAAAI/AAAAAAAAD6g/ZGypcZ-Aupw/s64/photo.jpg","userId":"15947158711655021589"}},"colab":{"base_uri":"https://localhost:8080/","height":493}},"source":["print(y_pred[:9])\n","print(y_test[:9])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[9.21644792e-12 1.64206654e-07 4.12715326e-06 5.18118313e-08\n","  3.60710914e-07 1.19364199e-10 1.91028942e-17 9.99993205e-01\n","  6.93901603e-10 2.16547733e-06]\n"," [5.40889467e-08 1.69114145e-07 9.99999523e-01 1.46104018e-10\n","  2.49118365e-10 2.76379197e-10 1.86010666e-07 5.70938193e-11\n","  3.31840759e-08 5.77983706e-14]\n"," [4.74322187e-12 9.99998212e-01 1.44369583e-08 4.05388431e-11\n","  4.17996176e-07 2.54959822e-08 1.08775011e-09 1.37989718e-06\n","  1.02745625e-08 4.62864662e-08]\n"," [9.97561336e-01 5.60426705e-10 2.58570680e-07 3.06075854e-09\n","  3.73771094e-08 2.24538826e-06 2.43556057e-03 3.25126370e-09\n","  2.37649175e-07 3.14335409e-07]\n"," [4.23311939e-13 1.81482950e-15 7.86186727e-10 1.84236959e-10\n","  9.99983191e-01 2.29293494e-11 1.76278692e-09 2.24722534e-08\n","  2.90249957e-09 1.67625349e-05]\n"," [2.40194128e-12 9.99997854e-01 3.53185499e-08 3.65423525e-11\n","  4.20740747e-07 3.70860032e-09 5.64602150e-11 1.75329569e-06\n","  6.25872021e-09 4.89122982e-08]\n"," [5.66966266e-12 3.16245767e-08 2.68834829e-05 7.12565873e-09\n","  9.99902487e-01 5.10662090e-09 2.52833431e-11 1.13078113e-05\n","  7.58177464e-07 5.85117596e-05]\n"," [1.78556181e-09 3.55827893e-07 2.53126541e-06 1.37054149e-05\n","  6.99014496e-03 9.28384325e-05 2.69033129e-09 7.17020521e-06\n","  6.03441822e-06 9.92887199e-01]\n"," [6.08340045e-03 6.70517938e-12 1.19962962e-07 1.85360953e-08\n","  5.62066407e-06 8.83319616e-01 1.04492076e-01 8.30368163e-10\n","  5.27623203e-03 8.23094626e-04]]\n","[7 2 1 0 4 1 4 9 5]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CT--y98_dr2T","colab_type":"code","colab":{}},"source":["layer_dict = dict([(layer.name, layer) for layer in model.layers])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2GY4Upv4dsUR","colab_type":"code","outputId":"43ac38b8-886a-40c2-e322-76150e3e9d0b","executionInfo":{"status":"error","timestamp":1557993460505,"user_tz":-330,"elapsed":1021,"user":{"displayName":"Anusha Shetty","photoUrl":"https://lh4.googleusercontent.com/-EhNj3Y4A6O8/AAAAAAAAAAI/AAAAAAAAD6g/ZGypcZ-Aupw/s64/photo.jpg","userId":"15947158711655021589"}},"colab":{"base_uri":"https://localhost:8080/","height":316}},"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","from keras import backend as K\n","%matplotlib inline\n","# util function to convert a tensor into a valid image\n","def deprocess_image(x):\n","    # normalize tensor: center on 0., ensure std is 0.1\n","    x -= x.mean()\n","    x /= (x.std() + 1e-5)\n","    x *= 0.1\n","\n","    # clip to [0, 1]\n","    x += 0.5\n","    x = np.clip(x, 0, 1)\n","\n","    # convert to RGB array\n","    x *= 255\n","    #x = x.transpose((1, 2, 0))\n","    x = np.clip(x, 0, 255).astype('uint8')\n","    return x\n","\n","def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n","                      layer_name = 'conv2d_14'):\n","    layer_output = layer_dict[layer_name].output\n","    img_ascs = list()\n","    for filter_index in range(layer_output.shape[3]):\n","        # build a loss function that maximizes the activation\n","        # of the nth filter of the layer considered\n","        loss = K.mean(layer_output[:, :, :, filter_index])\n","\n","        # compute the gradient of the input picture wrt this loss\n","        grads = K.gradients(loss, model.input)[0]\n","\n","        # normalization trick: we normalize the gradient\n","        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n","\n","        # this function returns the loss and grads given the input picture\n","        iterate = K.function([model.input], [loss, grads])\n","\n","        # step size for gradient ascent\n","        step = 5.\n","\n","        img_asc = np.array(img)\n","        # run gradient ascent for 20 steps\n","        for i in range(20):\n","            loss_value, grads_value = iterate([img_asc])\n","            img_asc += grads_value * step\n","\n","        img_asc = img_asc[0]\n","        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n","        \n","    if layer_output.shape[3] >= 35:\n","        plot_x, plot_y = 6, 6\n","    elif layer_output.shape[3] >= 23:\n","        plot_x, plot_y = 4, 6\n","    elif layer_output.shape[3] >= 11:\n","        plot_x, plot_y = 2, 6\n","    else:\n","        plot_x, plot_y = 1, 2\n","    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n","    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n","    ax[0, 0].set_title('Input image')\n","    fig.suptitle('Input image and %s filters' % (layer_name,))\n","    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n","    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n","        if x == 0 and y == 0:\n","            continue\n","        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n","        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n","\n","vis_img_in_filter()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-79-19229f66b51a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filter %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mplot_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mvis_img_in_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-79-19229f66b51a>\u001b[0m in \u001b[0;36mvis_img_in_filter\u001b[0;34m(img, layer_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n\u001b[1;32m     23\u001b[0m                       layer_name = 'conv2d_14'):\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mimg_ascs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilter_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'layer_dict' is not defined"]}]},{"cell_type":"code","metadata":{"id":"9tvptcn8dxvp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}