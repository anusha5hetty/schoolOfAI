{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 7B.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kf2Zx_cMN5U",
        "colab_type": "text"
      },
      "source": [
        "Importing required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkwXnw9OfHZl",
        "colab_type": "code",
        "outputId": "3526877a-7366-4485-921b-27429a5ef0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras import backend as K\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "% matplotlib inline\n",
        "np.random.seed(2017) \n",
        "\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqbZO4U7MT4i",
        "colab_type": "text"
      },
      "source": [
        "Getting CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHpnoCHZfO8g",
        "colab_type": "code",
        "outputId": "4229bcc4-dd7a-4122-f500-60e4783b3d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
        "num_train, img_channels, img_rows, img_cols =  train_features.shape\n",
        "num_test, _, _, _ =  test_features.shape\n",
        "num_classes = len(np.unique(train_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LThI7TusMZcF",
        "colab_type": "text"
      },
      "source": [
        "Plotting an image of each class using pyplot "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14HyBUXdfS6G",
        "colab_type": "code",
        "outputId": "048d3ca6-4f96-4d38-c4c6-67159a67f2c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "fig = plt.figure(figsize=(8,3))\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "    idx = np.where(train_labels[:]==i)[0]\n",
        "    features_idx = train_features[idx,::]\n",
        "    img_num = np.random.randint(features_idx.shape[0])\n",
        "    im = features_idx[img_num]\n",
        "    ax.set_title(class_names[i])\n",
        "    plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAADECAYAAAAvbXA5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUAMDAwMDg3PA/IAaGBgYGBicA/8XX+JaT2U4UocAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x216 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdmeqWMcNBhf",
        "colab_type": "text"
      },
      "source": [
        "Method to plot model history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmfsk76-fadV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAdVHdJlNIjX",
        "colab_type": "text"
      },
      "source": [
        "Method to get test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJMT4rjgfdZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5c5nDvxm6zR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = train_features.astype('float32')/255\n",
        "test_features = test_features.astype('float32')/255\n",
        "# convert class labels to binary class labels\n",
        "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = np_utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d18p0gSOtr2",
        "colab_type": "text"
      },
      "source": [
        "## ENAS Model - Using Upsampling2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEUgEUD2shxZ",
        "colab_type": "code",
        "outputId": "2c6d075d-582e-4115-aba4-c0594b580074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3819
        }
      },
      "source": [
        "# Using Upsampling2D\n",
        "\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, SeparableConv2D, UpSampling2D\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "\n",
        "visible = Input(shape=(32,32,3)) \n",
        "\n",
        "x1 = SeparableConv2D(24, (5, 5), border_mode='same')(visible) #32, RF: 5\n",
        "x1 = BatchNormalization()(x1)\n",
        "x1 = Activation('relu')(x1)\n",
        "x1 = Dropout(0.1)(x1)\n",
        "\n",
        "# Convolution block\n",
        "\n",
        "x2 = Convolution2D(48, 5, 5, border_mode='same')(x1) #32, RF: \n",
        "x2 = BatchNormalization()(x2)\n",
        "x2 = Activation('relu')(x2)\n",
        "x2 = Dropout(0.1)(x2)\n",
        "\n",
        "x3 = Convolution2D(72, 5, 5, border_mode='same')(x2)\n",
        "x3 = BatchNormalization()(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "x3 = Dropout(0.1)(x3)\n",
        "\n",
        "concat_x3_x1 = concatenate([x3, x1])\n",
        "x4 = SeparableConv2D(128, (5, 5), border_mode='same')(concat_x3_x1)\n",
        "x4 = BatchNormalization()(x4)\n",
        "x4 = Activation('relu')(x4)\n",
        "x4 = Dropout(0.1)(x4)\n",
        "\n",
        "# Trasition block\n",
        "concat_x4_x1 = concatenate([x4, x1])\n",
        "x5 = MaxPooling2D(pool_size=(2, 2))(concat_x4_x1)\n",
        "\n",
        "# Convolution block\n",
        "x6 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(x5)\n",
        "\n",
        "x6 = SeparableConv2D(24, (3, 3), border_mode='same')(x6)\n",
        "x6 = BatchNormalization()(x6)\n",
        "x6 = Activation('relu')(x6)\n",
        "x6 = Dropout(0.1)(x6)\n",
        "\n",
        "concat_x6_x4_x1 = concatenate([x6, x4, x1])\n",
        "x7 = Convolution2D(48, 5, 5, border_mode='same')(concat_x6_x4_x1)\n",
        "x7 = BatchNormalization()(x7)\n",
        "x7 = Activation('relu')(x7)\n",
        "x7 = Dropout(0.1)(x7)\n",
        "\n",
        "\n",
        "concat_x7_x6_x4_x3 = concatenate([x7, x6, x4, x3])\n",
        "x8 = SeparableConv2D(72, (3, 3), border_mode='same')(concat_x7_x6_x4_x3)\n",
        "x8 = BatchNormalization()(x8)\n",
        "x8 = Activation('relu')(x8)\n",
        "x8 = Dropout(0.1)(x8)\n",
        "\n",
        "\n",
        "concat_x8_x7_x6_x4_x3_x1 = concatenate([x8, x7, x6, x4, x3, x1])\n",
        "x9 = SeparableConv2D(128, (5, 5), border_mode='same')(concat_x8_x7_x6_x4_x3_x1)\n",
        "x9 = BatchNormalization()(x9)\n",
        "x9 = Activation('relu')(x9)\n",
        "x9 = Dropout(0.1)(x9)\n",
        "\n",
        "\n",
        "# Trasition block\n",
        "concat_x9_x8_x6_x4_x1 = concatenate([x9, x8, x6, x4, x1])\n",
        "x10 = MaxPooling2D(pool_size=(2, 2))(concat_x9_x8_x6_x4_x1)\n",
        "\n",
        "x10 = UpSampling2D(size=(2, 2), data_format=\"channels_last\")(x10)\n",
        "\n",
        "# Convolution block\n",
        "concat_x10_x7 = concatenate([x10, x7])\n",
        "x11 = Convolution2D(24, 5, 5, border_mode='same')(concat_x10_x7)\n",
        "x11 = BatchNormalization()(x11)\n",
        "x11 = Activation('relu')(x11)\n",
        "x11 = Dropout(0.1)(x11)\n",
        "\n",
        "\n",
        "concat_x11_x8_x2_x1 = concatenate([x11, x8, x2, x1])\n",
        "x12 = SeparableConv2D(48, (5, 5), border_mode='same')(concat_x11_x8_x2_x1)\n",
        "x12 = BatchNormalization()(x12)\n",
        "x12 = Activation('relu')(x12)\n",
        "x12 = Dropout(0.1)(x12)\n",
        "\n",
        "\n",
        "concat_x12_x11_x6_x3_x2 = concatenate([x12, x11, x6, x3, x2])\n",
        "x13 = Convolution2D(72, 3, 3, border_mode='same')(concat_x12_x11_x6_x3_x2)\n",
        "x13 = BatchNormalization()(x13)\n",
        "x13 = Activation('relu')(x13)\n",
        "x13 = Dropout(0.1)(x13)\n",
        "\n",
        "\n",
        "concat_x13_x12_x8_x6_x4_x3_x1 = concatenate([x13, x12, x8, x6, x4, x3, x1])\n",
        "x14 = SeparableConv2D(128, (5, 5), border_mode='same')(concat_x13_x12_x8_x6_x4_x3_x1)\n",
        "x14 = BatchNormalization()(x14)\n",
        "x14 = Activation('relu')(x14)\n",
        "x14 = Dropout(0.1)(x14)\n",
        "\n",
        "\n",
        "x15 = Convolution2D(10, 1, 1)(x14)\n",
        "last_layer = Convolution2D(10, 32, 32)(x15)\n",
        "\n",
        "flat = Flatten()(last_layer)\n",
        "output = Activation('softmax')(flat)\n",
        "\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0619 03:08:42.043196 140341739652992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0619 03:08:42.080658 140341739652992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(24, (5, 5), padding=\"same\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "W0619 03:08:42.088921 140341739652992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0619 03:08:42.138600 140341739652992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0619 03:08:42.139482 140341739652992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0619 03:08:44.850711 140341739652992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0619 03:08:44.922414 140341739652992 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), padding=\"same\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(72, (5, 5), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(128, (5, 5), padding=\"same\")`\n",
            "W0619 03:08:45.339910 140341739652992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0619 03:08:45.351049 140341739652992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(24, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(72, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(128, (5, 5), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(48, (5, 5), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(72, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(128, (5, 5), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:99: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (32, 32))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 32, 32, 24)   171         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 24)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 48)   28848       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 48)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 72)   86472       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 72)   288         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 72)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 72)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 96)   0           dropout_3[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 32, 32, 128)  14816       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 128)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 152)  0           dropout_4[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 152)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 152)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 32, 32, 24)   5040        up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 24)   96          separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 24)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 24)   0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 176)  0           dropout_5[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 48)   211248      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 48)   0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 272)  0           dropout_6[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 32, 32, 72)   22104       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 72)   288         separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 72)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 72)   0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 368)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 32, 32, 128)  56432       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 128)  0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 376)  0           dropout_8[0][0]                  \n",
            "                                                                 dropout_7[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 376)  0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 376)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 424)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 24)   254424      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 24)   96          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 24)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 24)   0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 168)  0           dropout_9[0][0]                  \n",
            "                                                                 dropout_7[0][0]                  \n",
            "                                                                 dropout_2[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 32, 32, 48)   12312       concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 48)   192         separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 48)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 48)   0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 216)  0           dropout_10[0][0]                 \n",
            "                                                                 dropout_9[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 72)   140040      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 72)   288         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 72)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 72)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 440)  0           dropout_11[0][0]                 \n",
            "                                                                 dropout_10[0][0]                 \n",
            "                                                                 dropout_7[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 32, 32, 128)  67448       concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 128)  0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 10)   1290        dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 1, 1, 10)     102410      conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 10)           0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 10)           0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,006,319\n",
            "Trainable params: 1,004,687\n",
            "Non-trainable params: 1,632\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Nv9lSJn_1M",
        "colab_type": "code",
        "outputId": "83b63d70-08b1-41e8-bf3a-85185462885e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0619 03:08:58.990066 140341739652992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R67iQF9dPVhy",
        "colab_type": "text"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ_XG_MxoGVD",
        "colab_type": "code",
        "outputId": "dac76470-3e59-47a9-d565-47b4ef2297d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7806
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128),\n",
        "                                 samples_per_epoch = train_features.shape[0], nb_epoch = 100, \n",
        "                                 validation_data = (test_features, test_labels), callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy\n",
        "print (\"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=390, epochs=100)`\n",
            "  if sys.path[0] == '':\n",
            "W0619 03:09:03.854578 140341739652992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "390/390 [==============================] - 154s 395ms/step - loss: 1.7481 - acc: 0.4343 - val_loss: 1.8181 - val_acc: 0.4459\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "390/390 [==============================] - 151s 388ms/step - loss: 1.3589 - acc: 0.5724 - val_loss: 14.3137 - val_acc: 0.1030\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 1.1841 - acc: 0.6322 - val_loss: 1.1486 - val_acc: 0.6071\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 1.0580 - acc: 0.6719 - val_loss: 1.1611 - val_acc: 0.6343\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.9734 - acc: 0.6947 - val_loss: 2.1348 - val_acc: 0.3731\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.9728 - acc: 0.7009 - val_loss: 1.0774 - val_acc: 0.6671\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.8865 - acc: 0.7232 - val_loss: 1.2970 - val_acc: 0.5582\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.8783 - acc: 0.7281 - val_loss: 0.8246 - val_acc: 0.7164\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.7811 - acc: 0.7580 - val_loss: 0.9439 - val_acc: 0.6913\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.7708 - acc: 0.7626 - val_loss: 0.8631 - val_acc: 0.7081\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "390/390 [==============================] - 148s 381ms/step - loss: 0.7181 - acc: 0.7809 - val_loss: 0.9279 - val_acc: 0.7119\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.7261 - acc: 0.7844 - val_loss: 0.8421 - val_acc: 0.7282\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.6432 - acc: 0.8081 - val_loss: 0.9295 - val_acc: 0.7083\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.6035 - acc: 0.8171 - val_loss: 1.9291 - val_acc: 0.5525\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.6309 - acc: 0.8123 - val_loss: 0.9966 - val_acc: 0.7237\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.5707 - acc: 0.8336 - val_loss: 0.8489 - val_acc: 0.7310\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.5149 - acc: 0.8480 - val_loss: 0.8114 - val_acc: 0.7532\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.4661 - acc: 0.8605 - val_loss: 0.8410 - val_acc: 0.7433\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.4527 - acc: 0.8669 - val_loss: 0.8622 - val_acc: 0.7470\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.4435 - acc: 0.8694 - val_loss: 0.8734 - val_acc: 0.7444\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.4149 - acc: 0.8768 - val_loss: 0.8574 - val_acc: 0.7533\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.3897 - acc: 0.8862 - val_loss: 0.9383 - val_acc: 0.7467\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.3643 - acc: 0.8946 - val_loss: 0.9450 - val_acc: 0.7416\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "390/390 [==============================] - 148s 381ms/step - loss: 0.3835 - acc: 0.8887 - val_loss: 0.9886 - val_acc: 0.7236\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.3576 - acc: 0.9011 - val_loss: 0.9908 - val_acc: 0.7482\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.3163 - acc: 0.9133 - val_loss: 1.0913 - val_acc: 0.7245\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.3040 - acc: 0.9144 - val_loss: 1.0767 - val_acc: 0.7432\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.3053 - acc: 0.9133 - val_loss: 1.0017 - val_acc: 0.7444\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.2750 - acc: 0.9229 - val_loss: 1.0881 - val_acc: 0.7438\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.2865 - acc: 0.9199 - val_loss: 1.0478 - val_acc: 0.7439\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.2547 - acc: 0.9288 - val_loss: 1.1076 - val_acc: 0.7430\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.2269 - acc: 0.9371 - val_loss: 1.1432 - val_acc: 0.7524\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "390/390 [==============================] - 148s 380ms/step - loss: 0.2090 - acc: 0.9379 - val_loss: 1.3176 - val_acc: 0.7391\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "390/390 [==============================] - 148s 381ms/step - loss: 0.1557 - acc: 0.9446 - val_loss: 1.2160 - val_acc: 0.7467\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.1384 - acc: 0.9499 - val_loss: 1.2139 - val_acc: 0.7547\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.1278 - acc: 0.9542 - val_loss: 1.2393 - val_acc: 0.7547\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.1202 - acc: 0.9567 - val_loss: 1.2412 - val_acc: 0.7565\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.1135 - acc: 0.9586 - val_loss: 1.2307 - val_acc: 0.7602\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.1032 - acc: 0.9624 - val_loss: 1.2940 - val_acc: 0.7550\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.1008 - acc: 0.9632 - val_loss: 1.3386 - val_acc: 0.7562\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.0974 - acc: 0.9645 - val_loss: 1.3755 - val_acc: 0.7526\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0942 - acc: 0.9655 - val_loss: 1.3298 - val_acc: 0.7533\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0884 - acc: 0.9683 - val_loss: 1.3873 - val_acc: 0.7520\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.0814 - acc: 0.9708 - val_loss: 1.3887 - val_acc: 0.7551\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "390/390 [==============================] - 148s 381ms/step - loss: 0.0772 - acc: 0.9720 - val_loss: 1.4233 - val_acc: 0.7533\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.0796 - acc: 0.9704 - val_loss: 1.4135 - val_acc: 0.7544\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0733 - acc: 0.9736 - val_loss: 1.4434 - val_acc: 0.7563\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.0730 - acc: 0.9735 - val_loss: 1.4238 - val_acc: 0.7585\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0689 - acc: 0.9742 - val_loss: 1.4716 - val_acc: 0.7497\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.0653 - acc: 0.9764 - val_loss: 1.5072 - val_acc: 0.7543\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0001769912.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.0630 - acc: 0.9776 - val_loss: 1.4639 - val_acc: 0.7550\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0001737217.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.0616 - acc: 0.9780 - val_loss: 1.5369 - val_acc: 0.7481\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0001705708.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.0577 - acc: 0.9791 - val_loss: 1.4869 - val_acc: 0.7611\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0001675322.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0594 - acc: 0.9784 - val_loss: 1.5241 - val_acc: 0.7515\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0001646.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0566 - acc: 0.9794 - val_loss: 1.5108 - val_acc: 0.7581\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0001617687.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0547 - acc: 0.9799 - val_loss: 1.5432 - val_acc: 0.7530\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0001590331.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0521 - acc: 0.9811 - val_loss: 1.5688 - val_acc: 0.7472\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0001563885.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0495 - acc: 0.9824 - val_loss: 1.5692 - val_acc: 0.7506\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0001538304.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0475 - acc: 0.9825 - val_loss: 1.5699 - val_acc: 0.7590\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0001513546.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.0485 - acc: 0.9824 - val_loss: 1.5415 - val_acc: 0.7606\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0001489573.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0476 - acc: 0.9825 - val_loss: 1.5330 - val_acc: 0.7573\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0001466347.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0465 - acc: 0.9836 - val_loss: 1.5488 - val_acc: 0.7582\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0001443835.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0427 - acc: 0.9846 - val_loss: 1.5637 - val_acc: 0.7585\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0001422003.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0425 - acc: 0.9848 - val_loss: 1.5831 - val_acc: 0.7603\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0001400822.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0402 - acc: 0.9860 - val_loss: 1.6097 - val_acc: 0.7590\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0001380262.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0406 - acc: 0.9859 - val_loss: 1.5773 - val_acc: 0.7591\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0001360297.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0385 - acc: 0.9865 - val_loss: 1.5953 - val_acc: 0.7574\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0001340902.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0410 - acc: 0.9855 - val_loss: 1.6039 - val_acc: 0.7623\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0001322052.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0384 - acc: 0.9866 - val_loss: 1.6242 - val_acc: 0.7588\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0001303724.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0367 - acc: 0.9871 - val_loss: 1.6266 - val_acc: 0.7652\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0001285898.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0348 - acc: 0.9882 - val_loss: 1.6261 - val_acc: 0.7612\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0001268553.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.0347 - acc: 0.9878 - val_loss: 1.6486 - val_acc: 0.7617\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0001251669.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0352 - acc: 0.9872 - val_loss: 1.6343 - val_acc: 0.7624\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0001235229.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0349 - acc: 0.9874 - val_loss: 1.6653 - val_acc: 0.7599\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0001219215.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0328 - acc: 0.9886 - val_loss: 1.6411 - val_acc: 0.7605\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0001203611.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0332 - acc: 0.9882 - val_loss: 1.6365 - val_acc: 0.7578\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0001188401.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0318 - acc: 0.9887 - val_loss: 1.6471 - val_acc: 0.7651\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0001173571.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0304 - acc: 0.9890 - val_loss: 1.6521 - val_acc: 0.7614\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0001159107.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0297 - acc: 0.9894 - val_loss: 1.6962 - val_acc: 0.7588\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.0001144994.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0327 - acc: 0.9879 - val_loss: 1.7032 - val_acc: 0.7555\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.0001131222.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0290 - acc: 0.9896 - val_loss: 1.6376 - val_acc: 0.7640\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.0001117776.\n",
            "390/390 [==============================] - 149s 383ms/step - loss: 0.0285 - acc: 0.9899 - val_loss: 1.6819 - val_acc: 0.7618\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.0001104647.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0291 - acc: 0.9898 - val_loss: 1.6611 - val_acc: 0.7602\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.0001091822.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0280 - acc: 0.9902 - val_loss: 1.6484 - val_acc: 0.7641\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.0001079292.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0279 - acc: 0.9900 - val_loss: 1.6594 - val_acc: 0.7642\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.0001067046.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0260 - acc: 0.9909 - val_loss: 1.6768 - val_acc: 0.7650\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.0001055075.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0273 - acc: 0.9901 - val_loss: 1.6981 - val_acc: 0.7663\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.0001043369.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0267 - acc: 0.9903 - val_loss: 1.6795 - val_acc: 0.7664\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0001031921.\n",
            "390/390 [==============================] - 149s 381ms/step - loss: 0.0254 - acc: 0.9909 - val_loss: 1.7077 - val_acc: 0.7632\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.0001020721.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0238 - acc: 0.9917 - val_loss: 1.7423 - val_acc: 0.7597\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0001009761.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0257 - acc: 0.9914 - val_loss: 1.6934 - val_acc: 0.7670\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 9.99034e-05.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0225 - acc: 0.9922 - val_loss: 1.7130 - val_acc: 0.7661\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 9.88533e-05.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0237 - acc: 0.9919 - val_loss: 1.7320 - val_acc: 0.7608\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 9.7825e-05.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0247 - acc: 0.9916 - val_loss: 1.7415 - val_acc: 0.7591\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 9.68179e-05.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0232 - acc: 0.9914 - val_loss: 1.7325 - val_acc: 0.7604\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 9.58313e-05.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0241 - acc: 0.9918 - val_loss: 1.7178 - val_acc: 0.7599\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 9.48647e-05.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0222 - acc: 0.9921 - val_loss: 1.7164 - val_acc: 0.7607\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 9.39173e-05.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0229 - acc: 0.9920 - val_loss: 1.7277 - val_acc: 0.7640\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 9.29887e-05.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0210 - acc: 0.9924 - val_loss: 1.7357 - val_acc: 0.7642\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 9.20782e-05.\n",
            "390/390 [==============================] - 149s 382ms/step - loss: 0.0212 - acc: 0.9927 - val_loss: 1.7260 - val_acc: 0.7645\n",
            "Model took 14881.74 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAFNCAYAAAC5cXZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data is: 76.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kw5VJ8XPMX8",
        "colab_type": "text"
      },
      "source": [
        "## ENAS Model - Using Conv2DTranspose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg8jUV91LRRs",
        "colab_type": "code",
        "outputId": "f65cc9a1-95d6-4689-c332-d32d432aa097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3819
        }
      },
      "source": [
        "# Using Conv2DTranspose\n",
        "\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, SeparableConv2D, Conv2DTranspose\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "\n",
        "visible = Input(shape=(32,32,3)) \n",
        "\n",
        "x1 = SeparableConv2D(24, (5, 5), border_mode='same')(visible)\n",
        "x1 = BatchNormalization()(x1)\n",
        "x1 = Activation('relu')(x1)\n",
        "x1 = Dropout(0.1)(x1)\n",
        "\n",
        "x2 = Convolution2D(48, 5, 5, border_mode='same')(x1)\n",
        "x2 = BatchNormalization()(x2)\n",
        "x2 = Activation('relu')(x2)\n",
        "x2 = Dropout(0.1)(x2)\n",
        "\n",
        "x3 = Convolution2D(72, 5, 5, border_mode='same')(x2)\n",
        "x3 = BatchNormalization()(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "x3 = Dropout(0.1)(x3)\n",
        "\n",
        "concat_x3_x1 = concatenate([x3, x1])\n",
        "x4 = SeparableConv2D(128, (5, 5), border_mode='same')(concat_x3_x1)\n",
        "x4 = BatchNormalization()(x4)\n",
        "x4 = Activation('relu')(x4)\n",
        "x4 = Dropout(0.1)(x4)\n",
        "\n",
        "# Trasition block\n",
        "concat_x4_x1 = concatenate([x4, x1])\n",
        "x5 = MaxPooling2D(pool_size=(2, 2))(concat_x4_x1)\n",
        "\n",
        "# Convolution block\n",
        "x6 = Conv2DTranspose(24, (2, 2), strides=(2, 2), border_mode='same')(x5)\n",
        "\n",
        "x6 = SeparableConv2D(24, (3, 3), border_mode='same')(x6)\n",
        "x6 = BatchNormalization()(x6)\n",
        "x6 = Activation('relu')(x6)\n",
        "x6 = Dropout(0.1)(x6)\n",
        "\n",
        "concat_x6_x4_x1 = concatenate([x6, x4, x1])\n",
        "x7 = Convolution2D(48, 5, 5, border_mode='same')(concat_x6_x4_x1)\n",
        "x7 = BatchNormalization()(x7)\n",
        "x7 = Activation('relu')(x7)\n",
        "x7 = Dropout(0.1)(x7)\n",
        "\n",
        "\n",
        "concat_x7_x6_x4_x3 = concatenate([x7, x6, x4, x3])\n",
        "x8 = SeparableConv2D(72, (3, 3), border_mode='same')(concat_x7_x6_x4_x3)\n",
        "x8 = BatchNormalization()(x8)\n",
        "x8 = Activation('relu')(x8)\n",
        "x8 = Dropout(0.1)(x8)\n",
        "\n",
        "\n",
        "concat_x8_x7_x6_x4_x3_x1 = concatenate([x8, x7, x6, x4, x3, x1])\n",
        "x9 = SeparableConv2D(128, (5, 5), border_mode='same')(concat_x8_x7_x6_x4_x3_x1)\n",
        "x9 = BatchNormalization()(x9)\n",
        "x9 = Activation('relu')(x9)\n",
        "x9 = Dropout(0.1)(x9)\n",
        "\n",
        "\n",
        "# Trasition block\n",
        "concat_x9_x8_x6_x4_x1 = concatenate([x9, x8, x6, x4, x1])\n",
        "x10 = MaxPooling2D(pool_size=(2, 2))(concat_x9_x8_x6_x4_x1)\n",
        "\n",
        "# Convolution block\n",
        "x10 = Conv2DTranspose(24, (2, 2), strides=(2, 2), border_mode='same')(x10)\n",
        "\n",
        "concat_x10_x7 = concatenate([x10, x7])\n",
        "x11 = Convolution2D(24, 5, 5, border_mode='same')(concat_x10_x7)\n",
        "x11 = BatchNormalization()(x11)\n",
        "x11 = Activation('relu')(x11)\n",
        "x11 = Dropout(0.1)(x11)\n",
        "\n",
        "\n",
        "concat_x11_x8_x2_x1 = concatenate([x11, x8, x2, x1])\n",
        "x12 = SeparableConv2D(48, (5, 5), border_mode='same')(concat_x11_x8_x2_x1)\n",
        "x12 = BatchNormalization()(x12)\n",
        "x12 = Activation('relu')(x12)\n",
        "x12 = Dropout(0.1)(x12)\n",
        "\n",
        "\n",
        "concat_x12_x11_x6_x3_x2 = concatenate([x12, x11, x6, x3, x2])\n",
        "x13 = Convolution2D(72, 3, 3, border_mode='same')(concat_x12_x11_x6_x3_x2)\n",
        "x13 = BatchNormalization()(x13)\n",
        "x13 = Activation('relu')(x13)\n",
        "x13 = Dropout(0.1)(x13)\n",
        "\n",
        "\n",
        "concat_x13_x12_x8_x6_x4_x3_x1 = concatenate([x13, x12, x8, x6, x4, x3, x1])\n",
        "x14 = SeparableConv2D(128, (5, 5), border_mode='same')(concat_x13_x12_x8_x6_x4_x3_x1)\n",
        "x14 = BatchNormalization()(x14)\n",
        "x14 = Activation('relu')(x14)\n",
        "x14 = Dropout(0.1)(x14)\n",
        "\n",
        "\n",
        "x15 = Convolution2D(10, 1, 1)(x14)\n",
        "last_layer = Convolution2D(10, 32, 32)(x15)\n",
        "\n",
        "flat = Flatten()(last_layer)\n",
        "output = Activation('softmax')(flat)\n",
        "\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0618 14:37:17.103788 140547216185216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0618 14:37:17.150958 140547216185216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(24, (5, 5), padding=\"same\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "W0618 14:37:17.161813 140547216185216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0618 14:37:17.216947 140547216185216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0618 14:37:17.218041 140547216185216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0618 14:37:20.007847 140547216185216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0618 14:37:20.087107 140547216185216 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), padding=\"same\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(72, (5, 5), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(128, (5, 5), padding=\"same\")`\n",
            "W0618 14:37:20.514886 140547216185216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(24, (2, 2), strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(24, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(72, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(128, (5, 5), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(24, (2, 2), strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(48, (5, 5), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(72, (3, 3), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(128, (5, 5), padding=\"same\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 32, 32, 24)   171         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 24)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 48)   28848       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 48)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 72)   86472       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 72)   288         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 72)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 72)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 96)   0           dropout_3[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 32, 32, 128)  14816       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 128)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 152)  0           dropout_4[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 152)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 24)   14616       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 32, 32, 24)   816         conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 24)   96          separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 24)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 24)   0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 176)  0           dropout_5[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 48)   211248      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 48)   0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 272)  0           dropout_6[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 32, 32, 72)   22104       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 72)   288         separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 72)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 72)   0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 368)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 32, 32, 128)  56432       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 128)  0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 376)  0           dropout_8[0][0]                  \n",
            "                                                                 dropout_7[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 376)  0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 24)   36120       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 72)   0           conv2d_transpose_2[0][0]         \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 24)   43224       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 24)   96          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 24)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 24)   0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 168)  0           dropout_9[0][0]                  \n",
            "                                                                 dropout_7[0][0]                  \n",
            "                                                                 dropout_2[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 32, 32, 48)   12312       concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 48)   192         separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 48)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 48)   0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 216)  0           dropout_10[0][0]                 \n",
            "                                                                 dropout_9[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 72)   140040      concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 72)   288         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 72)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 72)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 440)  0           dropout_11[0][0]                 \n",
            "                                                                 dropout_10[0][0]                 \n",
            "                                                                 dropout_7[0][0]                  \n",
            "                                                                 dropout_5[0][0]                  \n",
            "                                                                 dropout_4[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 32, 32, 128)  67448       concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 128)  0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 10)   1290        dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 1, 1, 10)     102410      conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 10)           0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 10)           0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 841,631\n",
            "Trainable params: 839,999\n",
            "Non-trainable params: 1,632\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:99: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (32, 32))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR4BUKhGMojm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BujrCLXPbNB",
        "colab_type": "text"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zp7s1jUMkQi",
        "colab_type": "code",
        "outputId": "789d2488-a09d-4dda-e062-42eab57c7e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7806
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128),\n",
        "                                 samples_per_epoch = train_features.shape[0], nb_epoch = 100, \n",
        "                                 validation_data = (test_features, test_labels), callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# plot model history\n",
        "plot_model_history(model_info)\n",
        "# compute test accuracy \n",
        "print (\"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=390, epochs=100)`\n",
            "  if sys.path[0] == '':\n",
            "W0618 14:39:38.275845 140547216185216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "390/390 [==============================] - 135s 345ms/step - loss: 1.7928 - acc: 0.4159 - val_loss: 1.5265 - val_acc: 0.4950\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "390/390 [==============================] - 128s 328ms/step - loss: 1.3693 - acc: 0.5659 - val_loss: 13.1950 - val_acc: 0.0990\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 1.2636 - acc: 0.6136 - val_loss: 9.7426 - val_acc: 0.1697\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 1.0682 - acc: 0.6643 - val_loss: 0.9637 - val_acc: 0.6712\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 1.0011 - acc: 0.6860 - val_loss: 1.0231 - val_acc: 0.6592\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.8840 - acc: 0.7187 - val_loss: 1.0373 - val_acc: 0.6593\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 1.1020 - acc: 0.6921 - val_loss: 1.2081 - val_acc: 0.6374\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.9319 - acc: 0.7279 - val_loss: 0.9061 - val_acc: 0.6986\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "390/390 [==============================] - 125s 321ms/step - loss: 0.8420 - acc: 0.7504 - val_loss: 1.0549 - val_acc: 0.6766\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.8457 - acc: 0.7537 - val_loss: 0.8615 - val_acc: 0.7279\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.7606 - acc: 0.7727 - val_loss: 0.9143 - val_acc: 0.7104\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.7242 - acc: 0.7904 - val_loss: 0.8550 - val_acc: 0.7146\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.6803 - acc: 0.8012 - val_loss: 0.9631 - val_acc: 0.6855\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.7474 - acc: 0.7839 - val_loss: 0.8510 - val_acc: 0.7314\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.6294 - acc: 0.8145 - val_loss: 1.7576 - val_acc: 0.6371\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.5301 - acc: 0.8208 - val_loss: 0.8180 - val_acc: 0.7416\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.4312 - acc: 0.8482 - val_loss: 0.7846 - val_acc: 0.7563\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.3971 - acc: 0.8616 - val_loss: 0.7912 - val_acc: 0.7589\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.3683 - acc: 0.8704 - val_loss: 0.8196 - val_acc: 0.7527\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.3464 - acc: 0.8780 - val_loss: 0.8974 - val_acc: 0.7400\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.3196 - acc: 0.8865 - val_loss: 0.8375 - val_acc: 0.7590\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.3009 - acc: 0.8933 - val_loss: 0.8813 - val_acc: 0.7547\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.2726 - acc: 0.9035 - val_loss: 0.8927 - val_acc: 0.7583\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.2570 - acc: 0.9081 - val_loss: 0.9471 - val_acc: 0.7522\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.2368 - acc: 0.9157 - val_loss: 0.9683 - val_acc: 0.7575\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.2213 - acc: 0.9207 - val_loss: 0.9799 - val_acc: 0.7565\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.2034 - acc: 0.9273 - val_loss: 0.9934 - val_acc: 0.7617\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.1921 - acc: 0.9307 - val_loss: 1.0435 - val_acc: 0.7496\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.1788 - acc: 0.9355 - val_loss: 1.0333 - val_acc: 0.7565\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.1646 - acc: 0.9409 - val_loss: 1.1113 - val_acc: 0.7599\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.1539 - acc: 0.9435 - val_loss: 1.1347 - val_acc: 0.7537\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.1437 - acc: 0.9476 - val_loss: 1.1828 - val_acc: 0.7592\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.1391 - acc: 0.9487 - val_loss: 1.1754 - val_acc: 0.7604\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.1257 - acc: 0.9543 - val_loss: 1.2191 - val_acc: 0.7553\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.1200 - acc: 0.9569 - val_loss: 1.2139 - val_acc: 0.7592\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.1140 - acc: 0.9588 - val_loss: 1.2459 - val_acc: 0.7558\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.1057 - acc: 0.9617 - val_loss: 1.2507 - val_acc: 0.7616\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0998 - acc: 0.9641 - val_loss: 1.2782 - val_acc: 0.7579\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0966 - acc: 0.9639 - val_loss: 1.3635 - val_acc: 0.7493\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0904 - acc: 0.9679 - val_loss: 1.3186 - val_acc: 0.7581\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0002180233.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0846 - acc: 0.9692 - val_loss: 1.3388 - val_acc: 0.7623\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0002130833.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0855 - acc: 0.9683 - val_loss: 1.3528 - val_acc: 0.7572\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0002083623.\n",
            "390/390 [==============================] - 126s 323ms/step - loss: 0.0782 - acc: 0.9717 - val_loss: 1.3958 - val_acc: 0.7600\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0002038459.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0746 - acc: 0.9733 - val_loss: 1.3868 - val_acc: 0.7586\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001995211.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0735 - acc: 0.9736 - val_loss: 1.4122 - val_acc: 0.7612\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001953761.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0715 - acc: 0.9742 - val_loss: 1.4194 - val_acc: 0.7615\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001913998.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0664 - acc: 0.9762 - val_loss: 1.4422 - val_acc: 0.7597\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001875821.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0647 - acc: 0.9765 - val_loss: 1.4284 - val_acc: 0.7616\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001839137.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0605 - acc: 0.9776 - val_loss: 1.5089 - val_acc: 0.7594\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.000180386.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0588 - acc: 0.9787 - val_loss: 1.4549 - val_acc: 0.7633\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 0.0001769912.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.0554 - acc: 0.9801 - val_loss: 1.4766 - val_acc: 0.7633\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 0.0001737217.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.0554 - acc: 0.9802 - val_loss: 1.5253 - val_acc: 0.7621\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 0.0001705708.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.0538 - acc: 0.9807 - val_loss: 1.4886 - val_acc: 0.7640\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 0.0001675322.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0514 - acc: 0.9815 - val_loss: 1.5411 - val_acc: 0.7535\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 0.0001646.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0500 - acc: 0.9819 - val_loss: 1.5312 - val_acc: 0.7611\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 0.0001617687.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0496 - acc: 0.9817 - val_loss: 1.4866 - val_acc: 0.7607\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 0.0001590331.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0460 - acc: 0.9838 - val_loss: 1.5231 - val_acc: 0.7618\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 0.0001563885.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0456 - acc: 0.9837 - val_loss: 1.5676 - val_acc: 0.7633\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 0.0001538304.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0429 - acc: 0.9848 - val_loss: 1.5273 - val_acc: 0.7604\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 0.0001513546.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0456 - acc: 0.9837 - val_loss: 1.5163 - val_acc: 0.7620\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: LearningRateScheduler setting learning rate to 0.0001489573.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0431 - acc: 0.9843 - val_loss: 1.5258 - val_acc: 0.7622\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: LearningRateScheduler setting learning rate to 0.0001466347.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0425 - acc: 0.9853 - val_loss: 1.5231 - val_acc: 0.7667\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: LearningRateScheduler setting learning rate to 0.0001443835.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0382 - acc: 0.9871 - val_loss: 1.5810 - val_acc: 0.7595\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: LearningRateScheduler setting learning rate to 0.0001422003.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0397 - acc: 0.9860 - val_loss: 1.5748 - val_acc: 0.7629\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: LearningRateScheduler setting learning rate to 0.0001400822.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0363 - acc: 0.9872 - val_loss: 1.5583 - val_acc: 0.7660\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: LearningRateScheduler setting learning rate to 0.0001380262.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0395 - acc: 0.9857 - val_loss: 1.5831 - val_acc: 0.7610\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: LearningRateScheduler setting learning rate to 0.0001360297.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0389 - acc: 0.9859 - val_loss: 1.5846 - val_acc: 0.7641\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: LearningRateScheduler setting learning rate to 0.0001340902.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0358 - acc: 0.9871 - val_loss: 1.6107 - val_acc: 0.7644\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: LearningRateScheduler setting learning rate to 0.0001322052.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0356 - acc: 0.9871 - val_loss: 1.5759 - val_acc: 0.7645\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: LearningRateScheduler setting learning rate to 0.0001303724.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0322 - acc: 0.9885 - val_loss: 1.5933 - val_acc: 0.7680\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: LearningRateScheduler setting learning rate to 0.0001285898.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0341 - acc: 0.9881 - val_loss: 1.5989 - val_acc: 0.7631\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: LearningRateScheduler setting learning rate to 0.0001268553.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0323 - acc: 0.9888 - val_loss: 1.5844 - val_acc: 0.7656\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: LearningRateScheduler setting learning rate to 0.0001251669.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0328 - acc: 0.9881 - val_loss: 1.6258 - val_acc: 0.7651\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: LearningRateScheduler setting learning rate to 0.0001235229.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0323 - acc: 0.9883 - val_loss: 1.6045 - val_acc: 0.7685\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: LearningRateScheduler setting learning rate to 0.0001219215.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0300 - acc: 0.9896 - val_loss: 1.6015 - val_acc: 0.7667\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: LearningRateScheduler setting learning rate to 0.0001203611.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0270 - acc: 0.9906 - val_loss: 1.6009 - val_acc: 0.7658\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: LearningRateScheduler setting learning rate to 0.0001188401.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0295 - acc: 0.9895 - val_loss: 1.6251 - val_acc: 0.7626\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: LearningRateScheduler setting learning rate to 0.0001173571.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0290 - acc: 0.9899 - val_loss: 1.6300 - val_acc: 0.7665\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: LearningRateScheduler setting learning rate to 0.0001159107.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0278 - acc: 0.9904 - val_loss: 1.6137 - val_acc: 0.7686\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: LearningRateScheduler setting learning rate to 0.0001144994.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0280 - acc: 0.9898 - val_loss: 1.6461 - val_acc: 0.7641\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: LearningRateScheduler setting learning rate to 0.0001131222.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0273 - acc: 0.9908 - val_loss: 1.6504 - val_acc: 0.7649\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: LearningRateScheduler setting learning rate to 0.0001117776.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0254 - acc: 0.9916 - val_loss: 1.6437 - val_acc: 0.7674\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: LearningRateScheduler setting learning rate to 0.0001104647.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0254 - acc: 0.9912 - val_loss: 1.6736 - val_acc: 0.7652\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: LearningRateScheduler setting learning rate to 0.0001091822.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0240 - acc: 0.9917 - val_loss: 1.6411 - val_acc: 0.7673\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: LearningRateScheduler setting learning rate to 0.0001079292.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0246 - acc: 0.9913 - val_loss: 1.6830 - val_acc: 0.7674\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: LearningRateScheduler setting learning rate to 0.0001067046.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0250 - acc: 0.9911 - val_loss: 1.6745 - val_acc: 0.7659\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: LearningRateScheduler setting learning rate to 0.0001055075.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0249 - acc: 0.9911 - val_loss: 1.6898 - val_acc: 0.7634\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: LearningRateScheduler setting learning rate to 0.0001043369.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0241 - acc: 0.9918 - val_loss: 1.6963 - val_acc: 0.7640\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: LearningRateScheduler setting learning rate to 0.0001031921.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0232 - acc: 0.9916 - val_loss: 1.7039 - val_acc: 0.7637\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: LearningRateScheduler setting learning rate to 0.0001020721.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0242 - acc: 0.9918 - val_loss: 1.6809 - val_acc: 0.7676\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: LearningRateScheduler setting learning rate to 0.0001009761.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.0237 - acc: 0.9911 - val_loss: 1.6923 - val_acc: 0.7659\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 00092: LearningRateScheduler setting learning rate to 9.99034e-05.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0221 - acc: 0.9924 - val_loss: 1.6743 - val_acc: 0.7674\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 00093: LearningRateScheduler setting learning rate to 9.88533e-05.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.0215 - acc: 0.9927 - val_loss: 1.6662 - val_acc: 0.7682\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 00094: LearningRateScheduler setting learning rate to 9.7825e-05.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.0206 - acc: 0.9929 - val_loss: 1.6918 - val_acc: 0.7619\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 00095: LearningRateScheduler setting learning rate to 9.68179e-05.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.0200 - acc: 0.9932 - val_loss: 1.7060 - val_acc: 0.7658\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 00096: LearningRateScheduler setting learning rate to 9.58313e-05.\n",
            "390/390 [==============================] - 125s 322ms/step - loss: 0.0210 - acc: 0.9929 - val_loss: 1.7078 - val_acc: 0.7649\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 00097: LearningRateScheduler setting learning rate to 9.48647e-05.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0200 - acc: 0.9930 - val_loss: 1.7189 - val_acc: 0.7661\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: LearningRateScheduler setting learning rate to 9.39173e-05.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0230 - acc: 0.9919 - val_loss: 1.7153 - val_acc: 0.7654\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 00099: LearningRateScheduler setting learning rate to 9.29887e-05.\n",
            "390/390 [==============================] - 126s 323ms/step - loss: 0.0220 - acc: 0.9928 - val_loss: 1.6810 - val_acc: 0.7712\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 00100: LearningRateScheduler setting learning rate to 9.20782e-05.\n",
            "390/390 [==============================] - 126s 322ms/step - loss: 0.0192 - acc: 0.9933 - val_loss: 1.7041 - val_acc: 0.7650\n",
            "Model took 12571.26 seconds to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAFNCAYAAAC5cXZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data is: 76.50\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}